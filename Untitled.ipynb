{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252 entries, 0 to 251\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Date       252 non-null    object\n",
      " 1   Open       252 non-null    object\n",
      " 2   High       252 non-null    object\n",
      " 3   Low        252 non-null    object\n",
      " 4   Close      252 non-null    object\n",
      " 5   Adj Close  252 non-null    object\n",
      " 6   Volume     252 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 13.9+ KB\n",
      "stock_info.shape:  (251, 6)\n",
      "stock_info[0]:  [1.73830005e+03 1.75369995e+03 1.72270996e+03 1.75253003e+03\n",
      " 1.75253003e+03 2.83950000e+06]\n",
      "price.shape:  (251, 5)\n",
      "price[0]:  [1738.300049 1753.699951 1722.709961 1752.530029 1752.530029]\n",
      "norm_price[0]:  [0.05828515 0.06628003 0.05019153 0.06567267 0.06567267]\n",
      "====================================================================================================\n",
      "volume.shape:  (251, 1)\n",
      "volume[0]:  [2839500.]\n",
      "norm_volume[0]:  [0.13333787]\n",
      "====================================================================================================\n",
      "x.shape:  (251, 6)\n",
      "x[0]:  [0.05828515 0.06628003 0.05019153 0.06567267 0.06567267 0.13333787]\n",
      "x[-1]:  [0.77663506 0.78687272 0.75762887 0.78017052 0.78017052 0.19575786]\n",
      "====================================================================================================\n",
      "y[0]:  [0.06567267]\n",
      "y[-1]:  [0.78017052]\n",
      "[[0.05828515 0.06628003 0.05019153 0.06567267 0.06567267 0.13333787]\n",
      " [0.06798806 0.06990376 0.06074073 0.06580765 0.06580765 0.09461392]\n",
      " [0.06391273 0.07085898 0.05611507 0.06203861 0.06203861 0.12996732]\n",
      " [0.06072514 0.06273425 0.05416305 0.05642135 0.05642135 0.12131281]\n",
      " [0.05865892 0.06250585 0.05449532 0.06213721 0.06213721 0.10879749]\n",
      " [0.06604644 0.07859435 0.06604124 0.07673575 0.07673575 0.17737301]\n",
      " [0.07989223 0.08877491 0.07907713 0.08872814 0.08872814 0.15660493]\n",
      " [0.09083592 0.10303598 0.08892029 0.09992627 0.09992627 0.14600981]\n",
      " [0.0995473  0.10313459 0.09072692 0.09073212 0.09073212 0.07095874]\n",
      " [0.09260105 0.09319809 0.07094207 0.08076437 0.08076437 0.20729266]\n",
      " [0.06955071 0.07623219 0.06292114 0.07472144 0.07472144 0.17020291]\n",
      " [0.07682403 0.08465281 0.06966491 0.0699089  0.0699089  0.12180308]\n",
      " [0.07136774 0.07136774 0.05916768 0.05941686 0.05941686 0.13226883]\n",
      " [0.06498215 0.06664348 0.05923517 0.06518983 0.06518983 0.15226066]\n",
      " [0.06470185 0.07312767 0.06208011 0.06410482 0.06410482 0.10632575]\n",
      " [0.06300942 0.06470705 0.05657192 0.05875753 0.05875753 0.11119433]\n",
      " [0.06003469 0.0643592  0.0569405  0.06369467 0.06369467 0.08282037]\n",
      " [0.0643592  0.07162732 0.06199184 0.06972201 0.06972201 0.15079668]\n",
      " [0.07214647 0.07421788 0.06695495 0.07003868 0.07003868 0.12695084]\n",
      " [0.07318477 0.07448265 0.06801924 0.07433208 0.07433208 0.15415362]\n",
      " [0.07890064 0.08616356 0.07857876 0.08546792 0.08546792 0.18814517]\n",
      " [0.08773141 0.08938227 0.08115893 0.08202594 0.08202594 0.1681942 ]\n",
      " [0.08019332 0.08667752 0.07685001 0.08630894 0.08630894 0.12062509]\n",
      " [0.09011949 0.09185864 0.08120564 0.08330823 0.08330823 0.29071905]\n",
      " [0.08422194 0.08668271 0.08227512 0.08668271 0.08668271 0.08546235]\n",
      " [0.08710326 0.0880169  0.08386889 0.08471511 0.08471511 0.        ]\n",
      " [0.09084112 0.12689617 0.0900572  0.12601883 0.12601883 0.34891053]\n",
      " [0.13336484 0.14295875 0.12458597 0.12655357 0.12655357 0.36124881]] -> [0.11465979]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:103: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-11-4ab81de4106f>:103: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if i is 0:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4ab81de4106f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;31m# 텐서플로우 플레이스홀더 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;31m# 입력 X, 출력 Y를 생성한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data_column_cnt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   3095\u001b[0m   \"\"\"\n\u001b[0;32m   3096\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3097\u001b[1;33m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[0;32m   3098\u001b[0m                        \"eager execution.\")\n\u001b[0;32m   3099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    " \n",
    "# 랜덤에 의해 똑같은 결과를 재현하도록 시드 설정\n",
    "# 하이퍼파라미터를 튜닝하기 위한 용도(흔들리면 무엇때문에 좋아졌는지 알기 어려움)\n",
    "tf.random.set_seed(777)\n",
    " \n",
    " \n",
    "# Standardization\n",
    "def data_standardization(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.mean()) / x_np.std()\n",
    " \n",
    "# 너무 작거나 너무 큰 값이 학습을 방해하는 것을 방지하고자 정규화한다\n",
    "# x가 양수라는 가정하에 최소값과 최대값을 이용하여 0~1사이의 값으로 변환\n",
    "# Min-Max scaling\n",
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7) # 1e-7은 0으로 나누는 오류 예방차원\n",
    " \n",
    "# 정규화된 값을 원래의 값으로 되돌린다\n",
    "# 정규화하기 이전의 org_x값과 되돌리고 싶은 x를 입력하면 역정규화된 값을 리턴한다\n",
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()\n",
    " \n",
    " \n",
    "# 하이퍼파라미터\n",
    "input_data_column_cnt = 6  # 입력데이터의 컬럼 개수(Variable 개수)\n",
    "output_data_column_cnt = 1 # 결과데이터의 컬럼 개수\n",
    " \n",
    "seq_length = 28            # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
    "rnn_cell_hidden_dim = 20   # 각 셀의 (hidden)출력 크기\n",
    "forget_bias = 1.0          # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 1     # stacked LSTM layers 개수\n",
    "keep_prob = 1.0            # dropout할 때 keep할 비율\n",
    " \n",
    "epoch_num = 1000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.01       # 학습률\n",
    " \n",
    " \n",
    "# 데이터를 로딩한다.\n",
    "stock_file_name = 'AMZN.csv' # 아마존 주가데이터 파일\n",
    "encoding = 'euc-kr' # 문자 인코딩\n",
    "names = ['Date','Open','High','Low','Close','Adj Close','Volume']\n",
    "raw_dataframe = pd.read_csv(stock_file_name, names=names, encoding=encoding) #판다스이용 csv파일 로딩\n",
    "raw_dataframe.info() # 데이터 정보 출력\n",
    " \n",
    "# raw_dataframe.drop('Date', axis=1, inplace=True) # 시간열을 제거하고 dataframe 재생성하지 않기\n",
    "del raw_dataframe['Date'] # 위 줄과 같은 효과\n",
    " \n",
    "stock_info = raw_dataframe.values[1:].astype(np.float) # 금액&거래량 문자열을 부동소수점형으로 변환한다\n",
    "print(\"stock_info.shape: \", stock_info.shape)\n",
    "print(\"stock_info[0]: \", stock_info[0])\n",
    " \n",
    " \n",
    "# 데이터 전처리\n",
    "# 가격과 거래량 수치의 차이가 많아나서 각각 별도로 정규화한다\n",
    " \n",
    "# 가격형태 데이터들을 정규화한다\n",
    "# ['Open','High','Low','Close','Adj Close','Volume']에서 'Adj Close'까지 취함\n",
    "# 곧, 마지막 열 Volume를 제외한 모든 열\n",
    "price = stock_info[:,:-1]\n",
    "norm_price = min_max_scaling(price) # 가격형태 데이터 정규화 처리\n",
    "print(\"price.shape: \", price.shape)\n",
    "print(\"price[0]: \", price[0])\n",
    "print(\"norm_price[0]: \", norm_price[0])\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    " \n",
    "# 거래량형태 데이터를 정규화한다\n",
    "# ['Open','High','Low','Close','Adj Close','Volume']에서 마지막 'Volume'만 취함\n",
    "# [:,-1]이 아닌 [:,-1:]이므로 주의하자! 스칼라가아닌 벡터값 산출해야만 쉽게 병합 가능\n",
    "volume = stock_info[:,-1:]\n",
    "norm_volume = min_max_scaling(volume) # 거래량형태 데이터 정규화 처리\n",
    "print(\"volume.shape: \", volume.shape)\n",
    "print(\"volume[0]: \", volume[0])\n",
    "print(\"norm_volume[0]: \", norm_volume[0])\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    " \n",
    "# 행은 그대로 두고 열을 우측에 붙여 합친다\n",
    "x = np.concatenate((norm_price, norm_volume), axis=1) # axis=1, 세로로 합친다\n",
    "print(\"x.shape: \", x.shape)\n",
    "print(\"x[0]: \", x[0])    # x의 첫 값\n",
    "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
    "print(\"=\"*100) # 화면상 구분용\n",
    " \n",
    "y = x[:, [-2]] # 타켓은 주식 종가이다\n",
    "print(\"y[0]: \",y[0])     # y의 첫 값\n",
    "print(\"y[-1]: \",y[-1])   # y의 마지막 값\n",
    " \n",
    " \n",
    "dataX = [] # 입력으로 사용될 Sequence Data\n",
    "dataY = [] # 출력(타켓)으로 사용\n",
    " \n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i : i+seq_length]\n",
    "    _y = y[i + seq_length] # 다음 나타날 주가(정답)\n",
    "    if i is 0:\n",
    "        print(_x, \"->\", _y) # 첫번째 행만 출력해 봄\n",
    "    dataX.append(_x) # dataX 리스트에 추가\n",
    "    dataY.append(_y) # dataY 리스트에 추가\n",
    " \n",
    " \n",
    "# 학습용/테스트용 데이터 생성\n",
    "# 전체 70%를 학습용 데이터로 사용\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "# 나머지(30%)를 테스트용 데이터로 사용\n",
    "test_size = len(dataY) - train_size\n",
    " \n",
    "# 데이터를 잘라 학습용 데이터 생성\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    " \n",
    "# 데이터를 잘라 테스트용 데이터 생성\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])\n",
    " \n",
    " \n",
    "# 텐서플로우 플레이스홀더 생성\n",
    "# 입력 X, 출력 Y를 생성한다\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, seq_length, input_data_column_cnt])\n",
    "print(\"X: \", X)\n",
    "Y = tf.compat.v1.placeholder(tf.float32, [None, 1])\n",
    "print(\"Y: \", Y)\n",
    " \n",
    "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"targets: \", targets)\n",
    " \n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"predictions: \", predictions)\n",
    " \n",
    " \n",
    "# 모델(LSTM 네트워크) 생성\n",
    "def lstm_cell():\n",
    "    # LSTM셀을 생성\n",
    "    # num_units: 각 Cell 출력 크기\n",
    "    # forget_bias:  to the biases of the forget gate \n",
    "    #              (default: 1)  in order to reduce the scale of forgetting in the beginning of the training.\n",
    "    # state_is_tuple: True ==> accepted and returned states are 2-tuples of the c_state and m_state.\n",
    "    # state_is_tuple: False ==> they are concatenated along the column axis.\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
    "                                        forget_bias=forget_bias, state_is_tuple=True, activation=tf.nn.softsign)\n",
    "    if keep_prob < 1.0:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n",
    " \n",
    "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
    "stackedRNNs = [lstm_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) if num_stacked_layers > 1 else lstm_cell()\n",
    " \n",
    "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "print(\"hypothesis: \", hypothesis)\n",
    " \n",
    "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
    "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
    "hypothesis = tf.contrib.layers.fully_connected(hypothesis[:, -1], output_data_column_cnt, activation_fn=tf.identity)\n",
    " \n",
    " \n",
    "# 손실함수로 평균제곱오차를 사용한다\n",
    "loss = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "# 최적화함수로 AdamOptimizer를 사용한다\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate) # LSTM과 궁합 별로임\n",
    " \n",
    "train = optimizer.minimize(loss)\n",
    " \n",
    "# RMSE(Root Mean Square Error)\n",
    "# 제곱오차의 평균을 구하고 다시 제곱근을 구하면 평균 오차가 나온다\n",
    "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets-predictions))) # 아래 코드와 같다\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    " \n",
    " \n",
    "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
    "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
    "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
    " \n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "# 학습한다\n",
    "start_time = datetime.datetime.now() # 시작시간을 기록한다\n",
    "print('학습을 시작합니다...')\n",
    "for epoch in range(epoch_num):\n",
    "    _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "    if ((epoch+1) % 100 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
    "        # 학습용데이터로 rmse오차를 구한다\n",
    "        train_predict = sess.run(hypothesis, feed_dict={X: trainX})\n",
    "        train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
    "        train_error_summary.append(train_error)\n",
    " \n",
    "        # 테스트용데이터로 rmse오차를 구한다\n",
    "        test_predict = sess.run(hypothesis, feed_dict={X: testX})\n",
    "        test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
    "        test_error_summary.append(test_error)\n",
    "        \n",
    "        # 현재 오류를 출력한다\n",
    "        print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
    "        \n",
    "end_time = datetime.datetime.now() # 종료시간을 기록한다\n",
    "elapsed_time = end_time - start_time # 경과시간을 구한다\n",
    "print('elapsed_time:',elapsed_time)\n",
    "print('elapsed_time per epoch:',elapsed_time/epoch_num)\n",
    " \n",
    " \n",
    "# 하이퍼파라미터 출력\n",
    "print('input_data_column_cnt:', input_data_column_cnt, end='')\n",
    "print(',output_data_column_cnt:', output_data_column_cnt, end='')\n",
    " \n",
    "print(',seq_length:', seq_length, end='')\n",
    "print(',rnn_cell_hidden_dim:', rnn_cell_hidden_dim, end='')\n",
    "print(',forget_bias:', forget_bias, end='')\n",
    "print(',num_stacked_layers:', num_stacked_layers, end='')\n",
    "print(',keep_prob:', keep_prob, end='')\n",
    " \n",
    "print(',epoch_num:', epoch_num, end='')\n",
    "print(',learning_rate:', learning_rate, end='')\n",
    " \n",
    "print(',train_error:', train_error_summary[-1], end='')\n",
    "print(',test_error:', test_error_summary[-1], end='')\n",
    "print(',min_test_error:', np.min(test_error_summary))\n",
    " \n",
    "# 결과 그래프 출력\n",
    "plt.figure(1)\n",
    "plt.plot(train_error_summary, 'gold')\n",
    "plt.plot(test_error_summary, 'b')\n",
    "plt.xlabel('Epoch(x100)')\n",
    "plt.ylabel('Root Mean Square Error')\n",
    " \n",
    "plt.figure(2)\n",
    "plt.plot(testY, 'r')\n",
    "plt.plot(test_predict, 'b')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "# sequence length만큼의 가장 최근 데이터를 슬라이싱한다\n",
    "recent_data = np.array([x[len(x)-seq_length : ]])\n",
    "print(\"recent_data.shape:\", recent_data.shape)\n",
    "print(\"recent_data:\", recent_data)\n",
    " \n",
    "# 내일 종가를 예측해본다\n",
    "test_predict = sess.run(hypothesis, feed_dict={X: recent_data})\n",
    " \n",
    "print(\"test_predict\", test_predict[0])\n",
    "test_predict = reverse_min_max_scaling(price,test_predict) # 금액데이터 역정규화한다\n",
    "print(\"Tomorrow's stock price\", test_predict[0]) # 예측한 주가를 출력한다\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "Student2 point = 70.00\n",
      "Highest Score Student = 2\n"
     ]
    }
   ],
   "source": [
    "n = int(input())\n",
    "sdt=[[]for i in range(n)]\n",
    "max=0\n",
    "index = 0\n",
    "\n",
    "for i in range(n):\n",
    "    total=0\n",
    "\n",
    "    for j in range(3):\n",
    "        point=int(input())\n",
    "        total+=point\n",
    "        sdt[i].append(point)\n",
    "\n",
    "    avg = total/3\n",
    "    sdt[i].append(avg)\n",
    "\n",
    "\n",
    "print(\"Student%d point = %.2f\" %((i + 1), sdt[i][-1]))\n",
    "\n",
    "if max < sdt[i][-1]:\n",
    "        max=sdt[i][-1]\n",
    "        idx=i+1\n",
    "\n",
    "elif min > sdt[i][-1]:\n",
    "        min=sdt[i][-1]\n",
    "        idx=i+1\n",
    "\n",
    "\n",
    "print(\"Highest Score Student =\",idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "Student1 point = 10.00\n",
      "Student2 point = 10.00\n",
      "Student3 point = 10.00\n",
      "Highest Score Student = 1\n",
      "Lowest Score Student = 1\n"
     ]
    }
   ],
   "source": [
    "n = int(input())\n",
    "max_index = 0\n",
    "min_index = 0\n",
    "\n",
    "students = []\n",
    "for i in range(n):\n",
    "    scores = []\n",
    "    total = 0\n",
    "    for j in range(3):\n",
    "        score = int(input())\n",
    "        scores.append(score)\n",
    "        total += score\n",
    "    scores.append(total/3)\n",
    "    students.append(scores)\n",
    "    i = 0\n",
    "for student in students:\n",
    "    print('Student%d point = %0.2f'%(i+1, student[3]))\n",
    "    i += 1\n",
    "\n",
    "max_value = students[0][3]\n",
    "min_value = students[0][3]\n",
    "i = 0\n",
    "for student in students:\n",
    "    if max_value < student[3]:\n",
    "        max_index = i\n",
    "    if min_value > student[3]:\n",
    "        min_index = i\n",
    "    i += 1\n",
    "\n",
    "print('Highest Score Student =', max_index + 1)\n",
    "print('Lowest Score Student =', min_index + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
